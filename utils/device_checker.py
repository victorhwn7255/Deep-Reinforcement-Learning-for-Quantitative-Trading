import torch

def comprehensive_device_test():
    """
    Comprehensive test for GPU (CUDA), MPS (Apple Silicon), and CPU devices
    """
    print("=" * 60)
    print("PYTORCH DEVICE COMPATIBILITY TEST")
    print("=" * 60)
    
    # PyTorch version
    print(f"PyTorch Version: {torch.__version__}")
    print()
    
    # Test CUDA (NVIDIA GPU)
    print("üîß CUDA (NVIDIA GPU) Test:")
    print(f"  ‚úì CUDA Available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"  ‚úì CUDA Version: {torch.version.cuda}")
        print(f"  ‚úì GPU Count: {torch.cuda.device_count()}")
        print(f"  ‚úì Current GPU: {torch.cuda.get_device_name(0)}")
        print(f"  ‚úì GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print("  ‚ùå CUDA not available")
    print()
    
    # Test MPS (Apple Silicon)
    print("üçé MPS (Apple Silicon) Test:")
    print(f"  ‚úì MPS Available: {torch.backends.mps.is_available()}")
    print(f"  ‚úì MPS Built: {torch.backends.mps.is_built()}")
    if torch.backends.mps.is_available():
        print("  ‚úì MPS ready for acceleration!")
    else:
        print("  ‚ùå MPS not available")
    print()
    
    # Test CPU
    print("üíª CPU Test:")
    print(f"  ‚úì CPU Threads: {torch.get_num_threads()}")
    print(f"  ‚úì CPU Count: {torch.get_num_interop_threads()}")
    print()
    
    # Device Selection Logic
    print("üéØ Device Selection:")
    if torch.cuda.is_available():
        selected_device = torch.device('cuda:0')
        device_type = "CUDA GPU"
    elif torch.backends.mps.is_available():
        selected_device = torch.device('mps')
        device_type = "MPS (Apple Silicon)"
    else:
        selected_device = torch.device('cpu')
        device_type = "CPU"
    
    print(f"  ‚úì Selected Device: {selected_device} ({device_type})")
    print()
    
    return selected_device, device_type