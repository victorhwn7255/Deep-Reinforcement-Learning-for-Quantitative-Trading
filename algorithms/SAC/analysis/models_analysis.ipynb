{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root : c:\\Users\\Admin\\Documents\\Codes\\drl_quant_trading\n",
      "SAC root     : c:\\Users\\Admin\\Documents\\Codes\\drl_quant_trading\\algorithms\\SAC\n",
      "Theme keys   : ['_meta', 'qualitative', 'red_amber_green', 'sequential', 'diverging', 'matplotlib_defaults', 'portfolio_assets', 'regime_colors', 'ablation_configs', 'performance']\n",
      "Asset colors : 6 entries\n",
      "Regime colors: ['stable', 'transition', 'crisis']\n",
      "Cluster clrs : {'C1': '#009BDE', 'C3': '#FF1F5B'}\n",
      "Display names: {'C1': 'SAC-Dir-HMM', 'C3': 'SAC-Dir-Base'}\n",
      "Teal cmap    : teal_seq\n",
      "\n",
      "Cell 1 complete - setup ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\4078853977.py:39: UserWarning: Overwriting the cmap 'teal_seq' that was already in the registry.\n",
      "  plt.colormaps.register(TEAL_CMAP, name=\"teal_seq\", force=True)\n"
     ]
    }
   ],
   "source": [
    "import sys, os, json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# -- project path ----------------------------------------------------------\n",
    "SAC_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "PROJ_ROOT = os.path.abspath(os.path.join(SAC_ROOT, \"..\", \"..\"))\n",
    "if SAC_ROOT not in sys.path:\n",
    "    sys.path.insert(0, SAC_ROOT)\n",
    "\n",
    "from config import SACConfig\n",
    "from data_utils import load_and_prepare_data\n",
    "from environment import Env\n",
    "from agent import Agent\n",
    "from evaluate import run_backtest, equity_curve, max_drawdown, sharpe, ann_vol, cagr\n",
    "\n",
    "# -- load theme ------------------------------------------------------------\n",
    "THEME_PATH = os.path.join(PROJ_ROOT, \"utils\", \"theme.json\")\n",
    "with open(THEME_PATH) as f:\n",
    "    THEME = json.load(f)\n",
    "\n",
    "ASSET_COLORS   = {k: v for k, v in THEME[\"portfolio_assets\"].items() if k != \"description\"}\n",
    "REGIME_COLORS  = {k: v for k, v in THEME[\"regime_colors\"].items()    if k != \"description\"}\n",
    "PERF_COLORS    = {k: v for k, v in THEME[\"performance\"].items()      if k != \"description\"}\n",
    "CLUSTER_COLORS  = {\"C1\": \"#009BDE\", \"C3\": \"#FF1F5B\"}\n",
    "CLUSTER_DISPLAY = {\"C1\": \"SAC-Dir-HMM\", \"C3\": \"SAC-Dir-Base\"}   # legends, titles, tables\n",
    "CLUSTER_SHORT   = {\"C1\": \"SD-HMM\", \"C3\": \"SD-Base\"}             # compact (heatmap rows)\n",
    "\n",
    "# register sequential teal colormap\n",
    "TEAL_CMAP = LinearSegmentedColormap.from_list(\n",
    "    \"teal_seq\", THEME[\"sequential\"][\"teal\"][\"colors\"]\n",
    ")\n",
    "plt.colormaps.register(TEAL_CMAP, name=\"teal_seq\", force=True)\n",
    "\n",
    "# -- rcParams (thesis quality) ---------------------------------------------\n",
    "mpl_def = THEME[\"matplotlib_defaults\"]\n",
    "plt.rcParams.update({\n",
    "    # colors from theme\n",
    "    \"figure.facecolor\":   mpl_def[\"background\"],\n",
    "    \"axes.facecolor\":     mpl_def[\"background\"],\n",
    "    \"text.color\":         mpl_def[\"text\"],\n",
    "    \"axes.labelcolor\":    mpl_def[\"text\"],\n",
    "    \"xtick.color\":        mpl_def[\"text\"],\n",
    "    \"ytick.color\":        mpl_def[\"text\"],\n",
    "    \"axes.edgecolor\":     mpl_def[\"grid\"],\n",
    "    \"grid.color\":         mpl_def[\"grid\"],\n",
    "    \"grid.alpha\":         mpl_def[\"grid_alpha\"],\n",
    "    # thesis conventions\n",
    "    \"axes.spines.top\":    False,\n",
    "    \"axes.spines.right\":  False,\n",
    "    \"axes.axisbelow\":     True,\n",
    "    \"axes.grid\":          True,\n",
    "    \"font.size\":          11,\n",
    "    \"axes.titlesize\":     14,\n",
    "    \"axes.titleweight\":   \"bold\",\n",
    "    \"legend.frameon\":     False,\n",
    "    \"savefig.dpi\":        300,\n",
    "    \"savefig.bbox\":       \"tight\",\n",
    "    \"figure.figsize\":     [10, 5],\n",
    "})\n",
    "\n",
    "# -- constants -------------------------------------------------------------\n",
    "SEEDS        = [42, 123, 456, 789, 1024]\n",
    "TICKERS      = [\"VNQ\", \"SPY\", \"TLT\", \"GLD\", \"BTC-USD\"]\n",
    "ASSET_LABELS = TICKERS + [\"Cash\"]\n",
    "TC_RATE      = 0.0001        # 1 bps\n",
    "LAG          = 5             # weekly rebalancing\n",
    "STEP_SIZE    = 5             # for annualization\n",
    "BM_EW        = [0.2, 0.2, 0.2, 0.2, 0.2, 0.0]\n",
    "BM_FW        = [0.10, 0.50, 0.30, 0.05, 0.05, 0.0]\n",
    "\n",
    "OUT_FIG = \"analysis_outputs/figures\"\n",
    "OUT_TBL = \"analysis_outputs/tables\"\n",
    "os.makedirs(OUT_FIG, exist_ok=True)\n",
    "os.makedirs(OUT_TBL, exist_ok=True)\n",
    "\n",
    "# -- sanity check ----------------------------------------------------------\n",
    "print(f\"Project root : {PROJ_ROOT}\")\n",
    "print(f\"SAC root     : {SAC_ROOT}\")\n",
    "print(f\"Theme keys   : {list(THEME.keys())}\")\n",
    "print(f\"Asset colors : {len(ASSET_COLORS)} entries\")\n",
    "print(f\"Regime colors: {list(REGIME_COLORS.keys())}\")\n",
    "print(f\"Cluster clrs : {CLUSTER_COLORS}\")\n",
    "print(f\"Display names: {CLUSTER_DISPLAY}\")\n",
    "cmap_check = plt.colormaps[\"teal_seq\"]\n",
    "print(f\"Teal cmap    : {cmap_check.name}\")\n",
    "print(\"\\nCell 1 complete - setup ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Inventory ===\n",
      "  cluster_1: 5 seeds — [42, 123, 456, 789, 1024]\n",
      "  cluster_3: 5 seeds — [42, 123, 456, 789, 1024]\n",
      "\n",
      "=== Key Config Differences ===\n",
      "Parameter                      Cluster 1                 Cluster 3                \n",
      "--------------------------------------------------------------------------------\n",
      "  Credit spread source         CREDIT_SPREAD_2010_202... CREDIT_SPREAD_2010_202...\n",
      "  HMM enabled                  True                      False                     *\n",
      "  HMM n_states                 3                         3                        \n",
      "  Macro feature count          11                        9                         *\n",
      "  Macro features               VIX_normalized, VIX_re... VIX_normalized, VIX_re... *\n",
      "  Yield curve features         Yes                       No                        *\n",
      "  Gamma                        0.995                     0.99                      *\n",
      "  Training timesteps           900,000                   690,000                   *\n",
      "\n",
      "(* = differs between clusters)\n",
      "\n",
      "Cell 2 complete — model discovery done\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 2 — Model Discovery\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "from config import Config\n",
    "\n",
    "MODELS_ROOT = os.path.join(SAC_ROOT, \"models\")\n",
    "CLUSTERS = [\"cluster_1\", \"cluster_3\"]\n",
    "\n",
    "# -- scan for seed folders with model weights + config ------------------\n",
    "model_inventory = {}  # {cluster: {seed: {\"weights\": path, \"config\": path}}}\n",
    "\n",
    "for cluster in CLUSTERS:\n",
    "    cluster_dir = os.path.join(MODELS_ROOT, cluster)\n",
    "    model_inventory[cluster] = {}\n",
    "    for seed in SEEDS:\n",
    "        seed_dir = os.path.join(cluster_dir, f\"seed_{seed}\")\n",
    "        weights = os.path.join(seed_dir, \"sac_best.pth\")\n",
    "        cfg_path = os.path.join(seed_dir, \"config.json\")\n",
    "        found_w = os.path.exists(weights)\n",
    "        found_c = os.path.exists(cfg_path)\n",
    "        if found_w and found_c:\n",
    "            model_inventory[cluster][seed] = {\n",
    "                \"weights\": weights,\n",
    "                \"config\": cfg_path,\n",
    "            }\n",
    "        else:\n",
    "            print(f\"  WARNING: {cluster}/seed_{seed} missing — weights={found_w}, config={found_c}\")\n",
    "\n",
    "print(\"=== Model Inventory ===\")\n",
    "for cluster, seeds_dict in model_inventory.items():\n",
    "    print(f\"  {cluster}: {len(seeds_dict)} seeds — {sorted(seeds_dict.keys())}\")\n",
    "\n",
    "# -- load one representative config per cluster for comparison ----------\n",
    "rep_cfgs = {}\n",
    "for cluster in CLUSTERS:\n",
    "    first_seed = sorted(model_inventory[cluster].keys())[0]\n",
    "    rep_cfgs[cluster] = Config.load_json(model_inventory[cluster][first_seed][\"config\"])\n",
    "\n",
    "c1, c3 = rep_cfgs[\"cluster_1\"], rep_cfgs[\"cluster_3\"]\n",
    "\n",
    "# -- print key config differences --------------------------------------\n",
    "print(\"\\n=== Key Config Differences ===\")\n",
    "print(f\"{'Parameter':<30} {'Cluster 1':<25} {'Cluster 3':<25}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "diffs = [\n",
    "    (\"Credit spread source\",\n",
    "     os.path.basename(c1.data.credit_spread_path),\n",
    "     os.path.basename(c3.data.credit_spread_path)),\n",
    "    (\"HMM enabled\",\n",
    "     str(c1.features.use_regime_hmm),\n",
    "     str(c3.features.use_regime_hmm)),\n",
    "    (\"HMM n_states\",\n",
    "     str(c1.features.hmm_n_states),\n",
    "     str(c3.features.hmm_n_states)),\n",
    "    (\"Macro feature count\",\n",
    "     str(len(c1.features.macro_feature_columns)),\n",
    "     str(len(c3.features.macro_feature_columns))),\n",
    "    (\"Macro features\",\n",
    "     \", \".join(c1.features.macro_feature_columns),\n",
    "     \", \".join(c3.features.macro_feature_columns)),\n",
    "    (\"Yield curve features\",\n",
    "     \"Yes\" if any(\"Yield\" in f for f in c1.features.macro_feature_columns) else \"No\",\n",
    "     \"Yes\" if any(\"Yield\" in f for f in c3.features.macro_feature_columns) else \"No\"),\n",
    "    (\"Gamma\",\n",
    "     str(c1.sac.gamma),\n",
    "     str(c3.sac.gamma)),\n",
    "    (\"Training timesteps\",\n",
    "     f\"{c1.training.total_timesteps:,}\",\n",
    "     f\"{c3.training.total_timesteps:,}\"),\n",
    "]\n",
    "\n",
    "for label, v1, v3 in diffs:\n",
    "    marker = \" *\" if v1 != v3 else \"\"\n",
    "    v1_disp = (v1[:22] + \"...\") if len(v1) > 25 else v1\n",
    "    v3_disp = (v3[:22] + \"...\") if len(v3) > 25 else v3\n",
    "    print(f\"  {label:<28} {v1_disp:<25} {v3_disp:<25}{marker}\")\n",
    "\n",
    "print(\"\\n(* = differs between clusters)\")\n",
    "print(\"\\nCell 2 complete — model discovery done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for cluster_1 (HMM=True) ...\n",
      "Downloading data for ['VNQ', 'SPY', 'TLT', 'GLD', 'BTC-USD']...\n",
      "  ✓ Downloaded 3758 rows\n",
      "  ✓ Date range: 2014-09-17 to 2024-12-30\n",
      "\n",
      "Fitting HMM on 2,805 training samples with 6 features...\n",
      "\n",
      "======================================================================\n",
      "HMM MODEL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Observation Features (6):\n",
      "  [0] SPY_logret\n",
      "  [1] VIX\n",
      "  [2] Credit_Spread\n",
      "  [3] VIX_term_struct\n",
      "  [4] YC_change_5d\n",
      "  [5] DXY_logret\n",
      "\n",
      "State Means (scaled space):\n",
      "----------------------------------------------------------------------\n",
      "Feature                   Stable  Transition      Crisis\n",
      "----------------------------------------------------------------------\n",
      "SPY_logret                0.0504      0.0221     -0.1189\n",
      "VIX                      -0.7964      0.0677      1.2307\n",
      "Credit_Spread            -0.1494     -0.4673      0.9759\n",
      "VIX_term_struct           0.7157     -0.1122     -1.0262\n",
      "YC_change_5d              0.0947      0.0585     -0.2496\n",
      "DXY_logret               -0.0117     -0.0151      0.0430\n",
      "\n",
      "Transition Matrix (row = from, col = to):\n",
      "--------------------------------------------------\n",
      "From/To           Stable  Transition      Crisis\n",
      "--------------------------------------------------\n",
      "Stable             97.5%        2.0%        0.5%\n",
      "Transition          2.0%       95.4%        2.6%\n",
      "Crisis              1.1%        3.9%       95.1%\n",
      "\n",
      "Average Stickiness: 96.0%\n",
      "\n",
      "Initial State Distribution:\n",
      "  Stable: 100.0%\n",
      "  Transition: 0.0%\n",
      "  Crisis: 0.0%\n",
      "\n",
      "Regime Distribution (Training Data):\n",
      "  Stable: 1,089 days (38.8%)\n",
      "  Transition: 1,025 days (36.5%)\n",
      "  Crisis: 691 days (24.6%)\n",
      "======================================================================\n",
      "\n",
      "  train: (2805, 39), test: (702, 39)\n",
      "  test range: 2023-01-29 → 2024-12-30\n",
      "  features: 24\n",
      "Loading data for cluster_3 (HMM=False) ...\n",
      "Downloading data for ['VNQ', 'SPY', 'TLT', 'GLD', 'BTC-USD']...\n",
      "  ✓ Downloaded 3758 rows\n",
      "  ✓ Date range: 2014-09-17 to 2024-12-30\n",
      "  train: (2805, 36), test: (702, 36)\n",
      "  test range: 2023-01-29 → 2024-12-30\n",
      "  features: 19\n",
      "\n",
      "=== Canonical Test Period ===\n",
      "  C1 test dates : 702\n",
      "  C3 test dates : 702\n",
      "  Intersection  : 702\n",
      "  Range         : 2023-01-29 → 2024-12-30\n",
      "  cluster_1 trimmed test: 702 rows\n",
      "  cluster_3 trimmed test: 702 rows\n",
      "\n",
      "=== Price Array ===\n",
      "  Shape: (702, 5)\n",
      "  Columns: ['VNQ', 'SPY', 'TLT', 'GLD', 'BTC-USD']\n",
      "\n",
      "=== Regime Probabilities (Cluster 1 — HMM ON) ===\n",
      "  Columns: ['RegimeP_stable', 'RegimeP_trans', 'RegimeP_crisis']\n",
      "  Shape: (702, 3)\n",
      "  Sample (first 3 rows):\n",
      "            RegimeP_stable  RegimeP_trans  RegimeP_crisis\n",
      "Date                                                     \n",
      "2023-01-29    5.199749e-05       0.999790        0.000158\n",
      "2023-01-30    5.434306e-09       0.998602        0.001398\n",
      "2023-01-31    1.887139e-08       0.998834        0.001166\n",
      "\n",
      "Cell 3 complete — data loaded\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 3 — Data Loading\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# Config paths are relative to algorithms/SAC/, so chdir there for data loading\n",
    "ANALYSIS_DIR = os.getcwd()\n",
    "os.chdir(SAC_ROOT)\n",
    "\n",
    "# -- load data per cluster using representative configs -----------------\n",
    "cluster_data = {}  # {cluster: {\"cfg\", \"df_train\", \"df_test\", \"feature_cols\"}}\n",
    "\n",
    "for cluster in CLUSTERS:\n",
    "    cfg = rep_cfgs[cluster]\n",
    "    print(f\"Loading data for {cluster} (HMM={cfg.features.use_regime_hmm}) ...\")\n",
    "    df_train, df_test, feature_cols = load_and_prepare_data(cfg)\n",
    "    cluster_data[cluster] = {\n",
    "        \"cfg\": cfg,\n",
    "        \"df_train\": df_train,\n",
    "        \"df_test\": df_test,\n",
    "        \"feature_cols\": feature_cols,\n",
    "    }\n",
    "    print(f\"  train: {df_train.shape}, test: {df_test.shape}\")\n",
    "    print(f\"  test range: {df_test.index[0].date()} → {df_test.index[-1].date()}\")\n",
    "    print(f\"  features: {len(feature_cols)}\")\n",
    "\n",
    "# restore CWD so output paths (analysis_outputs/) still work\n",
    "os.chdir(ANALYSIS_DIR)\n",
    "\n",
    "# -- compute canonical (shared) test date range ------------------------\n",
    "idx_c1 = cluster_data[\"cluster_1\"][\"df_test\"].index\n",
    "idx_c3 = cluster_data[\"cluster_3\"][\"df_test\"].index\n",
    "canonical_dates = idx_c1.intersection(idx_c3).sort_values()\n",
    "\n",
    "print(f\"\\n=== Canonical Test Period ===\")\n",
    "print(f\"  C1 test dates : {len(idx_c1)}\")\n",
    "print(f\"  C3 test dates : {len(idx_c3)}\")\n",
    "print(f\"  Intersection  : {len(canonical_dates)}\")\n",
    "print(f\"  Range         : {canonical_dates[0].date()} → {canonical_dates[-1].date()}\")\n",
    "\n",
    "# -- trim test DataFrames to canonical dates ----------------------------\n",
    "for cluster in CLUSTERS:\n",
    "    df_test = cluster_data[cluster][\"df_test\"]\n",
    "    cluster_data[cluster][\"df_test\"] = df_test.loc[df_test.index.isin(canonical_dates)].copy()\n",
    "\n",
    "# verify alignment\n",
    "for cluster in CLUSTERS:\n",
    "    n = len(cluster_data[cluster][\"df_test\"])\n",
    "    print(f\"  {cluster} trimmed test: {n} rows\")\n",
    "\n",
    "# -- extract price arrays on canonical dates ----------------------------\n",
    "df_test_canonical = cluster_data[\"cluster_1\"][\"df_test\"]\n",
    "prices_test = df_test_canonical[TICKERS].copy()\n",
    "\n",
    "print(f\"\\n=== Price Array ===\")\n",
    "print(f\"  Shape: {prices_test.shape}\")\n",
    "print(f\"  Columns: {list(prices_test.columns)}\")\n",
    "\n",
    "# -- extract regime probabilities (from HMM-enabled cluster = cluster_1) --\n",
    "regime_prob_cols = c1.features.regime_prob_columns\n",
    "regime_probs = cluster_data[\"cluster_1\"][\"df_test\"][regime_prob_cols].copy()\n",
    "print(f\"\\n=== Regime Probabilities (Cluster 1 — HMM ON) ===\")\n",
    "print(f\"  Columns: {list(regime_probs.columns)}\")\n",
    "print(f\"  Shape: {regime_probs.shape}\")\n",
    "print(f\"  Sample (first 3 rows):\")\n",
    "print(regime_probs.head(3).to_string())\n",
    "\n",
    "print(\"\\nCell 3 complete — data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for ['VNQ', 'SPY', 'TLT', 'GLD', 'BTC-USD']...\n",
      "  ✓ Downloaded 3758 rows\n",
      "  ✓ Date range: 2014-09-17 to 2024-12-30\n",
      "\n",
      "Fitting HMM on 2,805 training samples with 6 features...\n",
      "\n",
      "======================================================================\n",
      "HMM MODEL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Observation Features (6):\n",
      "  [0] SPY_logret\n",
      "  [1] VIX\n",
      "  [2] Credit_Spread\n",
      "  [3] VIX_term_struct\n",
      "  [4] YC_change_5d\n",
      "  [5] DXY_logret\n",
      "\n",
      "State Means (scaled space):\n",
      "----------------------------------------------------------------------\n",
      "Feature                   Stable  Transition      Crisis\n",
      "----------------------------------------------------------------------\n",
      "SPY_logret                0.0504      0.0221     -0.1189\n",
      "VIX                      -0.7964      0.0677      1.2307\n",
      "Credit_Spread            -0.1494     -0.4673      0.9759\n",
      "VIX_term_struct           0.7157     -0.1122     -1.0262\n",
      "YC_change_5d              0.0947      0.0585     -0.2496\n",
      "DXY_logret               -0.0117     -0.0151      0.0430\n",
      "\n",
      "Transition Matrix (row = from, col = to):\n",
      "--------------------------------------------------\n",
      "From/To           Stable  Transition      Crisis\n",
      "--------------------------------------------------\n",
      "Stable             97.5%        2.0%        0.5%\n",
      "Transition          2.0%       95.4%        2.6%\n",
      "Crisis              1.1%        3.9%       95.1%\n",
      "\n",
      "Average Stickiness: 96.0%\n",
      "\n",
      "Initial State Distribution:\n",
      "  Stable: 100.0%\n",
      "  Transition: 0.0%\n",
      "  Crisis: 0.0%\n",
      "\n",
      "Regime Distribution (Training Data):\n",
      "  Stable: 1,089 days (38.8%)\n",
      "  Transition: 1,025 days (36.5%)\n",
      "  Crisis: 691 days (24.6%)\n",
      "======================================================================\n",
      "\n",
      "  SAC-Dir-HMM seed=  42  Sharpe=1.651  CAGR=35.66%  MaxDD=-12.39%  FinalEq=2.333\n",
      "  SAC-Dir-HMM seed= 123  Sharpe=1.713  CAGR=40.45%  MaxDD=-7.31%  FinalEq=2.569\n",
      "  SAC-Dir-HMM seed= 456  Sharpe=2.033  CAGR=48.50%  MaxDD=-6.97%  FinalEq=2.999\n",
      "  SAC-Dir-HMM seed= 789  Sharpe=2.000  CAGR=39.23%  MaxDD=-7.85%  FinalEq=2.508\n",
      "  SAC-Dir-HMM seed=1024  Sharpe=1.799  CAGR=40.78%  MaxDD=-9.85%  FinalEq=2.586\n",
      "\n",
      "Downloading data for ['VNQ', 'SPY', 'TLT', 'GLD', 'BTC-USD']...\n",
      "  ✓ Downloaded 3758 rows\n",
      "  ✓ Date range: 2014-09-17 to 2024-12-30\n",
      "  SAC-Dir-Base seed=  42  Sharpe=1.613  CAGR=32.50%  MaxDD=-9.86%  FinalEq=2.185\n",
      "  SAC-Dir-Base seed= 123  Sharpe=1.642  CAGR=33.57%  MaxDD=-8.76%  FinalEq=2.234\n",
      "  SAC-Dir-Base seed= 456  Sharpe=1.793  CAGR=38.38%  MaxDD=-9.96%  FinalEq=2.465\n",
      "  SAC-Dir-Base seed= 789  Sharpe=1.599  CAGR=28.20%  MaxDD=-10.85%  FinalEq=1.994\n",
      "  SAC-Dir-Base seed=1024  Sharpe=1.302  CAGR=29.26%  MaxDD=-12.30%  FinalEq=2.040\n",
      "\n",
      "=== Agent Backtest Summary ===\n",
      "Cluster         Seed   Sharpe      CAGR     MaxDD    AnnVol   Calmar   FinalEq   AvgTurn\n",
      "----------------------------------------------------------------------------------------\n",
      "  SAC-Dir-HMM     42    1.651   35.66%  -12.39%   19.66%     2.88     2.333   0.1846\n",
      "  SAC-Dir-HMM    123    1.713   40.45%   -7.31%   21.14%     5.53     2.569   0.2156\n",
      "  SAC-Dir-HMM    456    2.033   48.50%   -6.97%   20.52%     6.96     2.999   0.2126\n",
      "  SAC-Dir-HMM    789    2.000   39.23%   -7.85%   17.33%     5.00     2.508   0.1847\n",
      "  SAC-Dir-HMM   1024    1.799   40.78%   -9.85%   20.14%     4.14     2.586   0.1772\n",
      "  SAC-Dir-HMM mean          1.839   40.92%   -8.87%   19.76%     4.90     2.599   0.1949\n",
      "  SAC-Dir-HMM std          0.152    4.20%    2.02%    1.31%     1.36     0.219   0.0159\n",
      "\n",
      "  SAC-Dir-Base    42    1.613   32.50%   -9.86%   18.53%     3.30     2.185   0.2160\n",
      "  SAC-Dir-Base   123    1.642   33.57%   -8.76%   18.69%     3.83     2.234   0.2188\n",
      "  SAC-Dir-Base   456    1.793   38.38%   -9.96%   19.15%     3.85     2.465   0.1954\n",
      "  SAC-Dir-Base   789    1.599   28.20%  -10.85%   16.39%     2.60     1.994   0.1992\n",
      "  SAC-Dir-Base  1024    1.302   29.26%  -12.30%   21.46%     2.38     2.040   0.2153\n",
      "  SAC-Dir-Base mean          1.590   32.38%  -10.35%   18.84%     3.19     2.184   0.2089\n",
      "  SAC-Dir-Base std          0.160    3.59%    1.18%    1.62%     0.61     0.166   0.0097\n",
      "\n",
      "Cell 4 complete — agent backtests done\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 4 — Agent Backtests\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")  # Dirichlet grad on CPU for stability\n",
    "\n",
    "# -- helper: patch seed config with fields dropped by Config.load_json --\n",
    "def patch_seed_config(seed_cfg, config_path):\n",
    "    \"\"\"Restore feature flags that Config.load_json drops (not in FeatureConfig fields).\n",
    "\n",
    "    Some models were trained with use_credit_regime=True, which added\n",
    "    Credit_Spread_regime to the feature columns. Since that flag isn't a\n",
    "    FeatureConfig dataclass field, load_json silently discards it.\n",
    "    \"\"\"\n",
    "    with open(config_path) as f:\n",
    "        raw = json.load(f)\n",
    "    raw_feat = raw.get(\"features\", {})\n",
    "\n",
    "    if raw_feat.get(\"use_credit_regime\", False):\n",
    "        if \"Credit_Spread_regime\" not in seed_cfg.features.macro_feature_columns:\n",
    "            seed_cfg.features.macro_feature_columns.append(\"Credit_Spread_regime\")\n",
    "    if raw_feat.get(\"use_vix_regime\", False):\n",
    "        if \"VIX_regime\" not in seed_cfg.features.macro_feature_columns:\n",
    "            seed_cfg.features.macro_feature_columns.append(\"VIX_regime\")\n",
    "\n",
    "# -- helper: load data for a specific seed config (with caching) -------\n",
    "_data_cache = {}  # keyed by (cluster, tuple(feature_cols)) to avoid redundant loads\n",
    "\n",
    "def load_seed_data(seed_cfg, cluster):\n",
    "    \"\"\"Load and prepare data for a seed config, caching by feature signature.\"\"\"\n",
    "    feat_key = tuple(sorted(seed_cfg.env.build_feature_columns(TICKERS, seed_cfg.features)))\n",
    "    cache_key = (cluster, feat_key)\n",
    "    if cache_key in _data_cache:\n",
    "        return _data_cache[cache_key]\n",
    "\n",
    "    prev_dir = os.getcwd()\n",
    "    os.chdir(SAC_ROOT)\n",
    "    df_train, df_test, feature_cols = load_and_prepare_data(seed_cfg)\n",
    "    os.chdir(prev_dir)\n",
    "\n",
    "    # trim to canonical dates\n",
    "    df_test = df_test.loc[df_test.index.isin(canonical_dates)].copy()\n",
    "    _data_cache[cache_key] = (df_train, df_test, feature_cols)\n",
    "    return df_train, df_test, feature_cols\n",
    "\n",
    "# -- cluster label mapping (internal key → folder name) --------------------\n",
    "CLUSTER_LABELS = {\"cluster_1\": \"C1\", \"cluster_3\": \"C3\"}\n",
    "\n",
    "# -- run backtests for all 10 seeds ------------------------------------\n",
    "agent_results = {}  # {cluster: {seed: {backtest_dict + metrics}}}\n",
    "\n",
    "for cluster in CLUSTERS:\n",
    "    agent_results[cluster] = {}\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        inv = model_inventory[cluster][seed]\n",
    "\n",
    "        # load this seed's own config\n",
    "        seed_cfg = Config.load_json(inv[\"config\"])\n",
    "        patch_seed_config(seed_cfg, inv[\"config\"])\n",
    "\n",
    "        # load data matching this seed's features (cached if identical to rep)\n",
    "        _, df_test_seed, _ = load_seed_data(seed_cfg, cluster)\n",
    "\n",
    "        # create env on this seed's test data\n",
    "        env = Env(df_test_seed, TICKERS, seed_cfg)\n",
    "\n",
    "        # create agent and load weights\n",
    "        state_dim = env.get_state_dim()\n",
    "        action_dim = env.get_action_dim()\n",
    "        agent = Agent(state_dim, action_dim, seed_cfg, device)\n",
    "        agent.load_model(inv[\"weights\"], map_location=\"cpu\")\n",
    "\n",
    "        # run deterministic backtest\n",
    "        bt = run_backtest(env, agent, deterministic=True)\n",
    "\n",
    "        # compute metrics (step_size=5 for weekly returns)\n",
    "        net = bt[\"net_returns\"]\n",
    "        eq = bt[\"equity\"]\n",
    "        metrics = {\n",
    "            \"sharpe\":     sharpe(net, step_size=STEP_SIZE),\n",
    "            \"cagr\":       cagr(eq, step_size=STEP_SIZE),\n",
    "            \"max_dd\":     max_drawdown(eq),\n",
    "            \"ann_vol\":    ann_vol(net, step_size=STEP_SIZE),\n",
    "            \"final_eq\":   eq[-1],\n",
    "            \"avg_turn\":   bt[\"turnover_oneway\"].mean(),\n",
    "        }\n",
    "        metrics[\"calmar\"] = metrics[\"cagr\"] / abs(metrics[\"max_dd\"]) if metrics[\"max_dd\"] != 0 else np.nan\n",
    "\n",
    "        agent_results[cluster][seed] = {**bt, **metrics}\n",
    "        label = CLUSTER_DISPLAY[CLUSTER_LABELS[cluster]]\n",
    "        print(f\"  {label} seed={seed:>4d}  Sharpe={metrics['sharpe']:.3f}  \"\n",
    "              f\"CAGR={metrics['cagr']:.2%}  MaxDD={metrics['max_dd']:.2%}  \"\n",
    "              f\"FinalEq={metrics['final_eq']:.3f}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "# -- summary table ------------------------------------------------------\n",
    "print(\"=== Agent Backtest Summary ===\")\n",
    "header = f\"{'Cluster':<14} {'Seed':>5}  {'Sharpe':>7}  {'CAGR':>8}  {'MaxDD':>8}  {'AnnVol':>8}  {'Calmar':>7}  {'FinalEq':>8}  {'AvgTurn':>8}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for cluster in CLUSTERS:\n",
    "    label = CLUSTER_DISPLAY[CLUSTER_LABELS[cluster]]\n",
    "    for seed in SEEDS:\n",
    "        r = agent_results[cluster][seed]\n",
    "        print(f\"  {label:<12} {seed:>5d}  {r['sharpe']:>7.3f}  {r['cagr']:>7.2%}  \"\n",
    "              f\"{r['max_dd']:>7.2%}  {r['ann_vol']:>7.2%}  {r['calmar']:>7.2f}  \"\n",
    "              f\"{r['final_eq']:>8.3f}  {r['avg_turn']:>7.4f}\")\n",
    "    # cluster mean +/- std\n",
    "    vals = {m: np.array([agent_results[cluster][s][m] for s in SEEDS])\n",
    "            for m in [\"sharpe\", \"cagr\", \"max_dd\", \"ann_vol\", \"calmar\", \"final_eq\", \"avg_turn\"]}\n",
    "    print(f\"  {label+' mean':<12} {'':>5}  {vals['sharpe'].mean():>7.3f}  {vals['cagr'].mean():>7.2%}  \"\n",
    "          f\"{vals['max_dd'].mean():>7.2%}  {vals['ann_vol'].mean():>7.2%}  {vals['calmar'].mean():>7.2f}  \"\n",
    "          f\"{vals['final_eq'].mean():>8.3f}  {vals['avg_turn'].mean():>7.4f}\")\n",
    "    print(f\"  {label+' std':<12} {'':>5}  {vals['sharpe'].std():>7.3f}  {vals['cagr'].std():>7.2%}  \"\n",
    "          f\"{vals['max_dd'].std():>7.2%}  {vals['ann_vol'].std():>7.2%}  {vals['calmar'].std():>7.2f}  \"\n",
    "          f\"{vals['final_eq'].std():>8.3f}  {vals['avg_turn'].std():>7.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"Cell 4 complete — agent backtests done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY B&H: 139 stepped returns, final equity = 1.468\n",
      "EW:  140 returns, final equity = 1.557\n",
      "FW:  140 returns, final equity = 1.290\n",
      "MV:  pre-computed 141 weight vectors\n",
      "MV:  140 returns, final equity = 1.372\n",
      "\n",
      "=== Benchmark Results (all step_size=5) ===\n",
      "Benchmark         Sharpe      CAGR     MaxDD    AnnVol   Calmar   FinalEq   AvgTurn\n",
      "-----------------------------------------------------------------------------------\n",
      "  SPY B&H          1.372   14.93%   -8.64%   10.57%     1.73     1.468   0.0000\n",
      "  Equal-Weight     1.366   17.27%   -9.74%   12.22%     1.77     1.557   0.0124\n",
      "  Fixed-Weight     1.038    9.61%  -10.06%    9.26%     0.96     1.290   0.0086\n",
      "  Mean-Variance    1.037   12.07%  -11.06%   11.64%     1.09     1.372   0.0927\n",
      "\n",
      "Cell 5 complete — benchmarks done\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 5 — Benchmark Strategies\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# -- Wrapper agents for Env-based benchmarks --------------------------------\n",
    "class FixedAgent:\n",
    "    \"\"\"Agent that always returns the same target weights.\"\"\"\n",
    "    def __init__(self, weights):\n",
    "        self.weights = np.array(weights, dtype=np.float32)\n",
    "    def select_action(self, obs, evaluate=True):\n",
    "        return self.weights.copy()\n",
    "\n",
    "class IndexedAgent:\n",
    "    \"\"\"Agent that returns pre-computed weights by step index.\"\"\"\n",
    "    def __init__(self, weight_sequence):\n",
    "        self.weights = list(weight_sequence)\n",
    "        self.idx = 0\n",
    "    def select_action(self, obs, evaluate=True):\n",
    "        w = self.weights[min(self.idx, len(self.weights) - 1)]\n",
    "        self.idx += 1\n",
    "        return w\n",
    "\n",
    "# -- Benchmark Env uses cluster_1 config/data (prices & TC identical) -------\n",
    "bm_cfg = rep_cfgs[\"cluster_1\"]\n",
    "bm_df  = cluster_data[\"cluster_1\"][\"df_test\"]\n",
    "\n",
    "# ── 1. Buy-and-Hold SPY (from raw prices, NO Env) ─────────────────────────\n",
    "spy_prices = prices_test[\"SPY\"].values\n",
    "spy_eq_daily = spy_prices / spy_prices[0]  # daily equity for smooth plotting\n",
    "\n",
    "# Derive 5-day returns matching Env rebalance cadence (pos: 4→9→14→…)\n",
    "spy_rets = []\n",
    "pos = LAG - 1\n",
    "while pos + LAG < len(spy_prices):\n",
    "    r = (spy_prices[pos + LAG] - spy_prices[pos]) / (spy_prices[pos] + 1e-12)\n",
    "    spy_rets.append(r)\n",
    "    pos += LAG\n",
    "spy_net = np.array(spy_rets, dtype=np.float64)\n",
    "spy_eq  = equity_curve(spy_net)\n",
    "\n",
    "print(f\"SPY B&H: {len(spy_net)} stepped returns, final equity = {spy_eq[-1]:.3f}\")\n",
    "\n",
    "# ── 2. Equal-Weight Rebalanced (through Env) ──────────────────────────────\n",
    "env_ew = Env(bm_df, TICKERS, bm_cfg)\n",
    "bm_ew_bt = run_backtest(env_ew, FixedAgent(BM_EW), deterministic=True)\n",
    "print(f\"EW:  {len(bm_ew_bt['net_returns'])} returns, final equity = {bm_ew_bt['equity'][-1]:.3f}\")\n",
    "\n",
    "# ── 3. Fixed-Weight Rebalanced (through Env) ──────────────────────────────\n",
    "env_fw = Env(bm_df, TICKERS, bm_cfg)\n",
    "bm_fw_bt = run_backtest(env_fw, FixedAgent(BM_FW), deterministic=True)\n",
    "print(f\"FW:  {len(bm_fw_bt['net_returns'])} returns, final equity = {bm_fw_bt['equity'][-1]:.3f}\")\n",
    "\n",
    "# ── 4. Mean-Variance Max Sharpe (pre-compute + through Env) ───────────────\n",
    "MV_LOOKBACK = 252\n",
    "\n",
    "# Full price history for rolling lookback (train + test)\n",
    "prices_full = pd.concat([\n",
    "    cluster_data[\"cluster_1\"][\"df_train\"][TICKERS],\n",
    "    cluster_data[\"cluster_1\"][\"df_test\"][TICKERS],\n",
    "]).sort_index()\n",
    "prices_full = prices_full[~prices_full.index.duplicated(keep=\"first\")]\n",
    "daily_rets_full = prices_full.pct_change().dropna()\n",
    "\n",
    "def mv_max_sharpe(rets_window):\n",
    "    \"\"\"Long-only max-Sharpe portfolio (5 risky assets).\"\"\"\n",
    "    mu  = rets_window.mean().values\n",
    "    cov = rets_window.cov().values\n",
    "    n   = len(mu)\n",
    "\n",
    "    def neg_sharpe(w):\n",
    "        port_ret = w @ mu\n",
    "        port_vol = np.sqrt(w @ cov @ w + 1e-12)\n",
    "        return -port_ret / (port_vol + 1e-8)\n",
    "\n",
    "    res = minimize(\n",
    "        neg_sharpe,\n",
    "        x0=np.ones(n) / n,\n",
    "        method=\"SLSQP\",\n",
    "        bounds=[(0.0, 1.0)] * n,\n",
    "        constraints=[{\"type\": \"eq\", \"fun\": lambda w: w.sum() - 1.0}],\n",
    "        options={\"maxiter\": 1000, \"ftol\": 1e-10},\n",
    "    )\n",
    "    return res.x if res.success else np.ones(n) / n\n",
    "\n",
    "# Pre-compute MV weights at each rebalance date\n",
    "test_dates  = prices_test.index\n",
    "n_env_steps = (len(test_dates) - LAG) // LAG + 2  # +2 safety margin\n",
    "ew_fallback = np.array(BM_EW, dtype=np.float32)\n",
    "\n",
    "mv_weights = []\n",
    "for i in range(n_env_steps):\n",
    "    pos_idx = LAG - 1 + i * LAG\n",
    "    if pos_idx >= len(test_dates):\n",
    "        mv_weights.append(ew_fallback.copy())\n",
    "        continue\n",
    "\n",
    "    date   = test_dates[pos_idx]\n",
    "    window = daily_rets_full.loc[daily_rets_full.index <= date].tail(MV_LOOKBACK)\n",
    "\n",
    "    if len(window) < MV_LOOKBACK:\n",
    "        w_risky = np.ones(len(TICKERS)) / len(TICKERS)\n",
    "    else:\n",
    "        try:\n",
    "            w_risky = mv_max_sharpe(window)\n",
    "        except Exception:\n",
    "            w_risky = np.ones(len(TICKERS)) / len(TICKERS)\n",
    "\n",
    "    w_full = np.concatenate([w_risky, [0.0]]).astype(np.float32)\n",
    "    mv_weights.append(w_full)\n",
    "\n",
    "print(f\"MV:  pre-computed {len(mv_weights)} weight vectors\")\n",
    "\n",
    "env_mv = Env(bm_df, TICKERS, bm_cfg)\n",
    "bm_mv_bt = run_backtest(env_mv, IndexedAgent(mv_weights), deterministic=True)\n",
    "print(f\"MV:  {len(bm_mv_bt['net_returns'])} returns, final equity = {bm_mv_bt['equity'][-1]:.3f}\")\n",
    "\n",
    "# ── Collect benchmark results ──────────────────────────────────────────────\n",
    "benchmark_results = {}\n",
    "\n",
    "for name, bt in [(\"SPY B&H\", None), (\"Equal-Weight\", bm_ew_bt),\n",
    "                  (\"Fixed-Weight\", bm_fw_bt), (\"Mean-Variance\", bm_mv_bt)]:\n",
    "    if name == \"SPY B&H\":\n",
    "        net, eq = spy_net, spy_eq\n",
    "        avg_turn = 0.0\n",
    "        bt_data = {\"net_returns\": net, \"equity\": eq, \"equity_daily\": spy_eq_daily}\n",
    "    else:\n",
    "        net, eq = bt[\"net_returns\"], bt[\"equity\"]\n",
    "        avg_turn = bt[\"turnover_oneway\"].mean()\n",
    "        bt_data = bt\n",
    "\n",
    "    metrics = {\n",
    "        \"sharpe\":   sharpe(net, step_size=STEP_SIZE),\n",
    "        \"cagr\":     cagr(eq, step_size=STEP_SIZE),\n",
    "        \"max_dd\":   max_drawdown(eq),\n",
    "        \"ann_vol\":  ann_vol(net, step_size=STEP_SIZE),\n",
    "        \"final_eq\": eq[-1],\n",
    "        \"avg_turn\": avg_turn,\n",
    "    }\n",
    "    metrics[\"calmar\"] = metrics[\"cagr\"] / abs(metrics[\"max_dd\"]) if metrics[\"max_dd\"] != 0 else np.nan\n",
    "    benchmark_results[name] = {**bt_data, **metrics}\n",
    "\n",
    "# ── Print benchmark summary ───────────────────────────────────────────────\n",
    "print(\"\\n=== Benchmark Results (all step_size=5) ===\")\n",
    "header = f\"{'Benchmark':<16} {'Sharpe':>7}  {'CAGR':>8}  {'MaxDD':>8}  {'AnnVol':>8}  {'Calmar':>7}  {'FinalEq':>8}  {'AvgTurn':>8}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "for name, r in benchmark_results.items():\n",
    "    print(f\"  {name:<14} {r['sharpe']:>7.3f}  {r['cagr']:>7.2%}  \"\n",
    "          f\"{r['max_dd']:>7.2%}  {r['ann_vol']:>7.2%}  {r['calmar']:>7.2f}  \"\n",
    "          f\"{r['final_eq']:>8.3f}  {r['avg_turn']:>7.4f}\")\n",
    "\n",
    "print(\"\\nCell 5 complete — benchmarks done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cluster: SAC-Dir-HMM (mean Sharpe = 1.839)\n",
      "\n",
      "================================================================================\n",
      "Table 5.1 — Best SAC Cluster vs Benchmarks\n",
      "================================================================================\n",
      "                      Sharpe            CAGR          Max DD        Ann. Vol         Calmar      Final Eq.   Avg. Turnover\n",
      "Strategy                                                                                                                  \n",
      "SAC-Dir-HMM    1.839 ± 0.152  40.92% ± 4.20%  -8.87% ± 2.02%  19.76% ± 1.31%  4.902 ± 1.365  2.599 ± 0.219  19.49% ± 1.59%\n",
      "SPY B&H                1.372          14.93%          -8.64%          10.57%          1.729          1.468           0.00%\n",
      "Equal-Weight           1.366          17.27%          -9.74%          12.22%          1.772          1.557           1.24%\n",
      "Fixed-Weight           1.038           9.61%         -10.06%           9.26%          0.955          1.290           0.86%\n",
      "Mean-Variance          1.037          12.07%         -11.06%          11.64%          1.091          1.372           9.27%\n",
      "\n",
      "================================================================================\n",
      "Table 5.2 — SAC-Dir-HMM vs SAC-Dir-Base\n",
      "================================================================================\n",
      "                                                               Sharpe            CAGR           Max DD        Ann. Vol         Calmar      Final Eq.   Avg. Turnover\n",
      "Cluster                                                                                                                                                             \n",
      "SAC-Dir-HMM                                             1.839 ± 0.152  40.92% ± 4.20%   -8.87% ± 2.02%  19.76% ± 1.31%  4.902 ± 1.365  2.599 ± 0.219  19.49% ± 1.59%\n",
      "SAC-Dir-Base                                            1.590 ± 0.160  32.38% ± 3.59%  -10.35% ± 1.18%  18.84% ± 1.62%  3.192 ± 0.612  2.184 ± 0.166  20.89% ± 0.97%\n",
      "Δ (SAC-Dir-HMM − SAC-Dir-Base)                                 +0.250          +8.54%           +1.47%          +0.91%         +1.710         +0.415          -1.40%\n",
      "CV(Sharpe)                      SAC-Dir-HMM=0.083, SAC-Dir-Base=0.100                                                                                               \n",
      "\n",
      "================================================================================\n",
      "Table 5.3 — All 10 Individual Seed Results\n",
      "================================================================================\n",
      "                  Sharpe    CAGR   Max DD Ann. Vol Calmar Final Eq. Avg. Turnover\n",
      "Cluster      Seed                                                                \n",
      "SAC-Dir-HMM  42    1.651  35.66%  -12.39%   19.66%  2.877     2.333        18.46%\n",
      "             123   1.713  40.45%   -7.31%   21.14%  5.534     2.569        21.56%\n",
      "             456   2.033  48.50%   -6.97%   20.52%  6.957     2.999        21.26%\n",
      "             789   2.000  39.23%   -7.85%   17.33%  5.000     2.508        18.47%\n",
      "             1024  1.799  40.78%   -9.85%   20.14%  4.142     2.586        17.72%\n",
      "SAC-Dir-Base 42    1.613  32.50%   -9.86%   18.53%  3.297     2.185        21.60%\n",
      "             123   1.642  33.57%   -8.76%   18.69%  3.832     2.234        21.88%\n",
      "             456   1.793  38.38%   -9.96%   19.15%  3.853     2.465        19.54%\n",
      "             789   1.599  28.20%  -10.85%   16.39%  2.599     1.994        19.92%\n",
      "             1024  1.302  29.26%  -12.30%   21.46%  2.378     2.040        21.53%\n",
      "\n",
      "Tables saved to: analysis_outputs/tables/\n",
      "Cell 6 complete — tables done\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 6 — Tables\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "METRICS = [\"sharpe\", \"cagr\", \"max_dd\", \"ann_vol\", \"calmar\", \"final_eq\", \"avg_turn\"]\n",
    "METRIC_LABELS = {\n",
    "    \"sharpe\": \"Sharpe\", \"cagr\": \"CAGR\", \"max_dd\": \"Max DD\",\n",
    "    \"ann_vol\": \"Ann. Vol\", \"calmar\": \"Calmar\", \"final_eq\": \"Final Eq.\",\n",
    "    \"avg_turn\": \"Avg. Turnover\",\n",
    "}\n",
    "PCT_METRICS = {\"cagr\", \"max_dd\", \"ann_vol\", \"avg_turn\"}\n",
    "\n",
    "def fmt_val(val, metric):\n",
    "    \"\"\"Format a single metric value.\"\"\"\n",
    "    if metric in PCT_METRICS:\n",
    "        return f\"{val:.2%}\"\n",
    "    return f\"{val:.3f}\"\n",
    "\n",
    "def fmt_mean_std(mean, std, metric):\n",
    "    \"\"\"Format mean ± std.\"\"\"\n",
    "    if metric in PCT_METRICS:\n",
    "        return f\"{mean:.2%} ± {std:.2%}\"\n",
    "    return f\"{mean:.3f} ± {std:.3f}\"\n",
    "\n",
    "# -- helper: collect per-seed metric arrays --------------------------------\n",
    "def cluster_metrics(cluster):\n",
    "    return {m: np.array([agent_results[cluster][s][m] for s in SEEDS]) for m in METRICS}\n",
    "\n",
    "c1_vals = cluster_metrics(\"cluster_1\")\n",
    "c3_vals = cluster_metrics(\"cluster_3\")\n",
    "\n",
    "# Display names\n",
    "D_C1 = CLUSTER_DISPLAY[\"C1\"]  # \"SAC-Dir-HMM\"\n",
    "D_C3 = CLUSTER_DISPLAY[\"C3\"]  # \"SAC-Dir-Base\"\n",
    "\n",
    "# Determine best cluster by mean Sharpe\n",
    "best_cluster = \"cluster_1\" if c1_vals[\"sharpe\"].mean() >= c3_vals[\"sharpe\"].mean() else \"cluster_3\"\n",
    "best_vals = c1_vals if best_cluster == \"cluster_1\" else c3_vals\n",
    "best_label = D_C1 if best_cluster == \"cluster_1\" else D_C3\n",
    "print(f\"Best cluster: {best_label} (mean Sharpe = {best_vals['sharpe'].mean():.3f})\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Table 5.1 — Best SAC Cluster vs Benchmarks\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "rows_51 = {}\n",
    "rows_51[best_label] = {\n",
    "    METRIC_LABELS[m]: fmt_mean_std(best_vals[m].mean(), best_vals[m].std(), m) for m in METRICS\n",
    "}\n",
    "for bm_name, bm in benchmark_results.items():\n",
    "    rows_51[bm_name] = {METRIC_LABELS[m]: fmt_val(bm[m], m) for m in METRICS}\n",
    "\n",
    "df_51 = pd.DataFrame(rows_51).T\n",
    "df_51.index.name = \"Strategy\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Table 5.1 — Best SAC Cluster vs Benchmarks\")\n",
    "print(\"=\" * 80)\n",
    "print(df_51.to_string())\n",
    "\n",
    "df_51.to_csv(os.path.join(OUT_TBL, \"table_5_1_best_vs_benchmarks.csv\"))\n",
    "df_51.to_latex(os.path.join(OUT_TBL, \"table_5_1_best_vs_benchmarks.tex\"),\n",
    "               caption=\"Best SAC cluster (mean $\\\\pm$ std over 5 seeds) vs benchmark strategies.\",\n",
    "               label=\"tab:best_vs_benchmarks\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Table 5.2 — Cluster Comparison\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "rows_52 = {}\n",
    "rows_52[D_C1] = {\n",
    "    METRIC_LABELS[m]: fmt_mean_std(c1_vals[m].mean(), c1_vals[m].std(), m) for m in METRICS\n",
    "}\n",
    "rows_52[D_C3] = {\n",
    "    METRIC_LABELS[m]: fmt_mean_std(c3_vals[m].mean(), c3_vals[m].std(), m) for m in METRICS\n",
    "}\n",
    "\n",
    "# Delta row\n",
    "delta_row = {}\n",
    "for m in METRICS:\n",
    "    d = c1_vals[m].mean() - c3_vals[m].mean()\n",
    "    if m in PCT_METRICS:\n",
    "        delta_row[METRIC_LABELS[m]] = f\"{d:+.2%}\"\n",
    "    else:\n",
    "        delta_row[METRIC_LABELS[m]] = f\"{d:+.3f}\"\n",
    "rows_52[f\"\\u0394 ({D_C1} \\u2212 {D_C3})\"] = delta_row\n",
    "\n",
    "# CV(Sharpe) row\n",
    "cv_c1 = c1_vals[\"sharpe\"].std() / c1_vals[\"sharpe\"].mean() if c1_vals[\"sharpe\"].mean() != 0 else np.nan\n",
    "cv_c3 = c3_vals[\"sharpe\"].std() / c3_vals[\"sharpe\"].mean() if c3_vals[\"sharpe\"].mean() != 0 else np.nan\n",
    "cv_row = {METRIC_LABELS[m]: \"\" for m in METRICS}\n",
    "cv_row[\"Sharpe\"] = f\"{D_C1}={cv_c1:.3f}, {D_C3}={cv_c3:.3f}\"\n",
    "rows_52[\"CV(Sharpe)\"] = cv_row\n",
    "\n",
    "df_52 = pd.DataFrame(rows_52).T\n",
    "df_52.index.name = \"Cluster\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Table 5.2 — {D_C1} vs {D_C3}\")\n",
    "print(\"=\" * 80)\n",
    "print(df_52.to_string())\n",
    "\n",
    "df_52.to_csv(os.path.join(OUT_TBL, \"table_5_2_cluster_comparison.csv\"))\n",
    "df_52.to_latex(os.path.join(OUT_TBL, \"table_5_2_cluster_comparison.tex\"),\n",
    "               caption=\"Cluster comparison: mean $\\\\pm$ std over 5 seeds, delta, and coefficient of variation.\",\n",
    "               label=\"tab:cluster_comparison\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Table 5.3 — All 10 Individual Seed Results\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "rows_53 = []\n",
    "for cluster in CLUSTERS:\n",
    "    label = CLUSTER_DISPLAY[CLUSTER_LABELS[cluster]]\n",
    "    for seed in SEEDS:\n",
    "        r = agent_results[cluster][seed]\n",
    "        row = {\"Cluster\": label, \"Seed\": seed}\n",
    "        for m in METRICS:\n",
    "            row[METRIC_LABELS[m]] = fmt_val(r[m], m)\n",
    "        rows_53.append(row)\n",
    "\n",
    "df_53 = pd.DataFrame(rows_53).set_index([\"Cluster\", \"Seed\"])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Table 5.3 — All 10 Individual Seed Results\")\n",
    "print(\"=\" * 80)\n",
    "print(df_53.to_string())\n",
    "\n",
    "df_53.to_csv(os.path.join(OUT_TBL, \"table_5_3_all_seeds.csv\"))\n",
    "df_53.to_latex(os.path.join(OUT_TBL, \"table_5_3_all_seeds.tex\"),\n",
    "               caption=\"Per-seed backtest results for reproducibility.\",\n",
    "               label=\"tab:all_seeds\")\n",
    "\n",
    "print(f\"\\nTables saved to: {OUT_TBL}/\")\n",
    "print(\"Cell 6 complete — tables done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\1854700102.py:66: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\1854700102.py:94: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 7 complete — F01, F02, F03 saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\1854700102.py:141: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 7 — Group 1: Headline Performance (F01–F03)\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# -- Equity date axes ------------------------------------------------------\n",
    "test_dates = prices_test.index\n",
    "\n",
    "def equity_dates(n_eq_points):\n",
    "    \"\"\"Build date array for an equity curve with n_eq_points.\"\"\"\n",
    "    return pd.DatetimeIndex([\n",
    "        test_dates[min(LAG - 1 + i * LAG, len(test_dates) - 1)]\n",
    "        for i in range(n_eq_points)\n",
    "    ])\n",
    "\n",
    "# -- Cluster equity statistics ---------------------------------------------\n",
    "def cluster_equity_stats(cluster):\n",
    "    eqs = np.vstack([agent_results[cluster][s][\"equity\"] for s in SEEDS])\n",
    "    return eqs.mean(axis=0), eqs.std(axis=0)\n",
    "\n",
    "c1_eq_mean, c1_eq_std = cluster_equity_stats(\"cluster_1\")\n",
    "c3_eq_mean, c3_eq_std = cluster_equity_stats(\"cluster_3\")\n",
    "env_dates = equity_dates(len(c1_eq_mean))\n",
    "spy_dates = equity_dates(len(spy_eq))\n",
    "\n",
    "# -- Benchmark style definitions -------------------------------------------\n",
    "BM_GREY = [\"#555555\", \"#777777\", \"#999999\", \"#444444\"]\n",
    "BM_LS   = [\"--\", \"-.\", \":\", (0, (3, 1, 1, 1))]\n",
    "BM_NAMES = [\"SPY B&H\", \"Equal-Weight\", \"Fixed-Weight\", \"Mean-Variance\"]\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F01 — Equity Curves: Cluster Means ± 1σ + Benchmarks\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Cluster bands + means\n",
    "ax.fill_between(env_dates, c1_eq_mean - c1_eq_std, c1_eq_mean + c1_eq_std,\n",
    "                color=CLUSTER_COLORS[\"C1\"], alpha=0.15)\n",
    "ax.plot(env_dates, c1_eq_mean, color=CLUSTER_COLORS[\"C1\"], lw=2.5,\n",
    "        label=f\"{CLUSTER_DISPLAY['C1']} mean \\u00b1 1\\u03c3\")\n",
    "\n",
    "ax.fill_between(env_dates, c3_eq_mean - c3_eq_std, c3_eq_mean + c3_eq_std,\n",
    "                color=CLUSTER_COLORS[\"C3\"], alpha=0.15)\n",
    "ax.plot(env_dates, c3_eq_mean, color=CLUSTER_COLORS[\"C3\"], lw=2.5,\n",
    "        label=f\"{CLUSTER_DISPLAY['C3']} mean \\u00b1 1\\u03c3\")\n",
    "\n",
    "# Benchmark lines\n",
    "bm_curves = [\n",
    "    (spy_dates, spy_eq),\n",
    "    (env_dates, benchmark_results[\"Equal-Weight\"][\"equity\"]),\n",
    "    (env_dates, benchmark_results[\"Fixed-Weight\"][\"equity\"]),\n",
    "    (env_dates, benchmark_results[\"Mean-Variance\"][\"equity\"]),\n",
    "]\n",
    "for (dates, eq), name, grey, ls in zip(bm_curves, BM_NAMES, BM_GREY, BM_LS):\n",
    "    ax.plot(dates, eq, color=grey, ls=ls, lw=1.5, label=name)\n",
    "\n",
    "ax.axhline(1.0, color=\"#CCCCCC\", lw=0.8, zorder=0)\n",
    "ax.set_ylabel(\"Equity ($1 initial)\")\n",
    "ax.set_title(\"F01 — Equity Curves: SAC Clusters vs Benchmarks\")\n",
    "ax.legend(loc=\"upper left\", fontsize=9, ncol=2)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F01_equity_curves.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F02 — Per-Seed Equity Curves with Cluster Means\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for cluster, ckey in [(\"cluster_1\", \"C1\"), (\"cluster_3\", \"C3\")]:\n",
    "    color = CLUSTER_COLORS[ckey]\n",
    "    for seed in SEEDS:\n",
    "        eq = agent_results[cluster][seed][\"equity\"]\n",
    "        ax.plot(env_dates, eq, color=color, alpha=0.25, lw=1.0)\n",
    "\n",
    "# Bold cluster means on top\n",
    "ax.plot(env_dates, c1_eq_mean, color=CLUSTER_COLORS[\"C1\"], lw=3.0,\n",
    "        label=f\"{CLUSTER_DISPLAY['C1']} mean\")\n",
    "ax.plot(env_dates, c3_eq_mean, color=CLUSTER_COLORS[\"C3\"], lw=3.0,\n",
    "        label=f\"{CLUSTER_DISPLAY['C3']} mean\")\n",
    "\n",
    "ax.axhline(1.0, color=\"#CCCCCC\", lw=0.8, zorder=0)\n",
    "ax.set_ylabel(\"Equity ($1 initial)\")\n",
    "ax.set_title(\"F02 — Per-Seed Equity Curves (10 seeds)\")\n",
    "ax.legend(loc=\"upper left\", fontsize=10)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F02_per_seed_equity.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F03 — Grouped Bar Chart: Sharpe, CAGR, MaxDD\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "bar_metrics = [\"sharpe\", \"cagr\", \"max_dd\"]\n",
    "bar_titles  = [\"Sharpe Ratio\", \"CAGR\", \"Max Drawdown\"]\n",
    "bar_fmts    = [\"{:.2f}\", \"{:.1%}\", \"{:.1%}\"]\n",
    "\n",
    "strategy_names = [CLUSTER_DISPLAY[\"C1\"], CLUSTER_DISPLAY[\"C3\"]] + BM_NAMES\n",
    "strategy_colors = [\n",
    "    CLUSTER_COLORS[\"C1\"], CLUSTER_COLORS[\"C3\"],\n",
    "    BM_GREY[0], BM_GREY[1], BM_GREY[2], BM_GREY[3],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, metric, title, fmt in zip(axes, bar_metrics, bar_titles, bar_fmts):\n",
    "    means = [c1_vals[metric].mean(), c3_vals[metric].mean()]\n",
    "    errs  = [c1_vals[metric].std(),  c3_vals[metric].std()]\n",
    "    for bm_name in BM_NAMES:\n",
    "        means.append(benchmark_results[bm_name][metric])\n",
    "        errs.append(0.0)\n",
    "\n",
    "    x = np.arange(len(strategy_names))\n",
    "    bars = ax.bar(x, means, color=strategy_colors, edgecolor=\"white\", lw=0.5,\n",
    "                  yerr=errs, capsize=4, error_kw={\"lw\": 1.2, \"capthick\": 1.2})\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(strategy_names, rotation=35, ha=\"right\", fontsize=8)\n",
    "    ax.set_title(title, fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    # Value labels on bars\n",
    "    for bar, val in zip(bars, means):\n",
    "        y = bar.get_height()\n",
    "        offset = -0.015 if y < 0 else 0.005\n",
    "        va = \"top\" if y < 0 else \"bottom\"\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, y + offset,\n",
    "                fmt.format(val), ha=\"center\", va=va, fontsize=8)\n",
    "\n",
    "    ax.axhline(0, color=\"#CCCCCC\", lw=0.8, zorder=0)\n",
    "\n",
    "plt.suptitle(\"F03 — Performance Comparison: Clusters vs Benchmarks\",\n",
    "             fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F03_grouped_bar_chart.png\"), dpi=300,\n",
    "            bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Cell 7 complete — F01, F02, F03 saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\2401467062.py:36: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\2401467062.py:62: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(arr, axis=0), np.nanstd(arr, axis=0)\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\quant_trading\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\2401467062.py:91: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 8 complete — F04, F05, F06 saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\2401467062.py:134: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 8 — Group 2: Risk Analysis (F04–F06)\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# -- Drawdown helper -------------------------------------------------------\n",
    "def drawdown_series(eq):\n",
    "    \"\"\"Return drawdown series (negative values) from equity curve.\"\"\"\n",
    "    eq = np.asarray(eq, dtype=np.float64)\n",
    "    peak = np.maximum.accumulate(eq)\n",
    "    return eq / (peak + 1e-12) - 1.0\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F04 — Drawdown Underwater Plot\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "dd_c1 = drawdown_series(c1_eq_mean)\n",
    "dd_c3 = drawdown_series(c3_eq_mean)\n",
    "dd_spy = drawdown_series(spy_eq)\n",
    "\n",
    "ax.fill_between(env_dates, dd_c1, 0, color=CLUSTER_COLORS[\"C1\"], alpha=0.35,\n",
    "                label=CLUSTER_DISPLAY[\"C1\"])\n",
    "ax.fill_between(env_dates, dd_c3, 0, color=CLUSTER_COLORS[\"C3\"], alpha=0.35,\n",
    "                label=CLUSTER_DISPLAY[\"C3\"])\n",
    "ax.plot(spy_dates, dd_spy, color=BM_GREY[0], ls=\"--\", lw=1.5, label=\"SPY B&H\")\n",
    "\n",
    "ax.set_ylabel(\"Drawdown\")\n",
    "ax.set_title(\"F04 — Drawdown Underwater Plot\")\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.legend(loc=\"lower left\", fontsize=9)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F04_drawdown.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F05 — Rolling Sharpe (30-step ≈ 6 months)\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "ROLL_WIN = 30  # 30 weekly steps ≈ 6 months\n",
    "\n",
    "def rolling_sharpe(rets, window=ROLL_WIN):\n",
    "    \"\"\"Compute rolling annualized Sharpe ratio.\"\"\"\n",
    "    n = len(rets)\n",
    "    out = np.full(n, np.nan)\n",
    "    periods_per_year = 252 / STEP_SIZE\n",
    "    for i in range(window - 1, n):\n",
    "        chunk = rets[i - window + 1 : i + 1]\n",
    "        mu = chunk.mean()\n",
    "        sd = chunk.std(ddof=1)\n",
    "        out[i] = (mu / sd) * np.sqrt(periods_per_year) if sd > 1e-12 else 0.0\n",
    "    return out\n",
    "\n",
    "# Per-seed rolling Sharpes → cluster stats\n",
    "def cluster_rolling_sharpe(cluster):\n",
    "    all_rs = []\n",
    "    for seed in SEEDS:\n",
    "        rs = rolling_sharpe(agent_results[cluster][seed][\"net_returns\"])\n",
    "        all_rs.append(rs)\n",
    "    arr = np.vstack(all_rs)\n",
    "    return np.nanmean(arr, axis=0), np.nanstd(arr, axis=0)\n",
    "\n",
    "c1_rs_mean, c1_rs_std = cluster_rolling_sharpe(\"cluster_1\")\n",
    "c3_rs_mean, c3_rs_std = cluster_rolling_sharpe(\"cluster_3\")\n",
    "\n",
    "# Date axis for rolling Sharpe (aligned with net_returns, so env_dates[1:])\n",
    "rs_dates = env_dates[1:]  # equity has n+1 points, returns has n\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.fill_between(rs_dates, c1_rs_mean - c1_rs_std, c1_rs_mean + c1_rs_std,\n",
    "                color=CLUSTER_COLORS[\"C1\"], alpha=0.15)\n",
    "ax.plot(rs_dates, c1_rs_mean, color=CLUSTER_COLORS[\"C1\"], lw=2,\n",
    "        label=f\"{CLUSTER_DISPLAY['C1']} mean \\u00b1 1\\u03c3\")\n",
    "\n",
    "ax.fill_between(rs_dates, c3_rs_mean - c3_rs_std, c3_rs_mean + c3_rs_std,\n",
    "                color=CLUSTER_COLORS[\"C3\"], alpha=0.15)\n",
    "ax.plot(rs_dates, c3_rs_mean, color=CLUSTER_COLORS[\"C3\"], lw=2,\n",
    "        label=f\"{CLUSTER_DISPLAY['C3']} mean \\u00b1 1\\u03c3\")\n",
    "\n",
    "ax.axhline(0, color=\"#CCCCCC\", lw=0.8, zorder=0)\n",
    "ax.set_ylabel(\"Rolling Sharpe Ratio\")\n",
    "ax.set_title(\"F05 — Rolling Sharpe (6-month window)\")\n",
    "ax.legend(loc=\"upper left\", fontsize=9)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F05_rolling_sharpe.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F06 — Risk-Return Scatter with Iso-Sharpe Lines\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "# Iso-Sharpe diagonal lines\n",
    "vol_range = np.linspace(0.001, 0.25, 200)\n",
    "for sr in [0.5, 1.0, 1.5, 2.0]:\n",
    "    ax.plot(vol_range, sr * vol_range, color=\"#E0E0E0\", lw=0.8, ls=\"--\", zorder=0)\n",
    "    ax.text(vol_range[-1] + 0.002, sr * vol_range[-1],\n",
    "            f\"SR={sr:.1f}\", fontsize=7, color=\"#AAAAAA\", va=\"center\")\n",
    "\n",
    "# Per-seed dots\n",
    "for cluster, ckey in [(\"cluster_1\", \"C1\"), (\"cluster_3\", \"C3\")]:\n",
    "    for seed in SEEDS:\n",
    "        r = agent_results[cluster][seed]\n",
    "        ax.scatter(r[\"ann_vol\"], r[\"cagr\"], color=CLUSTER_COLORS[ckey],\n",
    "                   s=60, alpha=0.7, edgecolors=\"white\", lw=0.5, zorder=3)\n",
    "\n",
    "# Cluster mean markers (larger)\n",
    "for cluster, ckey in [(\"cluster_1\", \"C1\"), (\"cluster_3\", \"C3\")]:\n",
    "    vals = cluster_metrics(cluster)\n",
    "    ax.scatter(vals[\"ann_vol\"].mean(), vals[\"cagr\"].mean(),\n",
    "               color=CLUSTER_COLORS[ckey], s=180, marker=\"D\",\n",
    "               edgecolors=\"black\", lw=1.2, zorder=4,\n",
    "               label=CLUSTER_DISPLAY[ckey])\n",
    "\n",
    "# Benchmark markers\n",
    "bm_markers = [\"s\", \"^\", \"v\", \"P\"]\n",
    "for (name, r), mkr in zip(benchmark_results.items(), bm_markers):\n",
    "    ax.scatter(r[\"ann_vol\"], r[\"cagr\"], color=BM_GREY[0], marker=mkr,\n",
    "               s=100, edgecolors=\"black\", lw=0.8, zorder=4, label=name)\n",
    "\n",
    "ax.set_xlabel(\"Annualized Volatility\")\n",
    "ax.set_ylabel(\"CAGR\")\n",
    "ax.xaxis.set_major_formatter(mticker.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.set_title(\"F06 — Risk-Return Scatter\")\n",
    "ax.legend(loc=\"lower right\", fontsize=8, ncol=3)\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F06_risk_return_scatter.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Cell 8 complete — F04, F05, F06 saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\1849276981.py:49: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\1849276981.py:83: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\1849276981.py:120: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 9 complete — F07, F08, F09 saved\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 9 — Group 3: Portfolio Behavior (F07–F09)\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# -- Average weights per cluster -------------------------------------------\n",
    "def cluster_avg_weights(cluster):\n",
    "    \"\"\"Average portfolio weights across all seeds and all steps.\"\"\"\n",
    "    all_w = np.vstack([agent_results[cluster][s][\"weights\"] for s in SEEDS])\n",
    "    return all_w.mean(axis=0)\n",
    "\n",
    "c1_avg_w = cluster_avg_weights(\"cluster_1\")\n",
    "c3_avg_w = cluster_avg_weights(\"cluster_3\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F07 — Average Weight Grouped Bar Chart\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(len(ASSET_LABELS))\n",
    "width = 0.35\n",
    "\n",
    "bars_c1 = ax.bar(x - width / 2, c1_avg_w, width, color=CLUSTER_COLORS[\"C1\"],\n",
    "                 edgecolor=\"white\", lw=0.5, label=CLUSTER_DISPLAY[\"C1\"])\n",
    "bars_c3 = ax.bar(x + width / 2, c3_avg_w, width, color=CLUSTER_COLORS[\"C3\"],\n",
    "                 edgecolor=\"white\", lw=0.5, label=CLUSTER_DISPLAY[\"C3\"])\n",
    "\n",
    "# Value labels\n",
    "for bars in [bars_c1, bars_c3]:\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0.01:\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, h + 0.005,\n",
    "                    f\"{h:.1%}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(ASSET_LABELS, fontsize=10)\n",
    "ax.set_ylabel(\"Average Weight\")\n",
    "ax.set_title(\"F07 — Average Portfolio Weights by Cluster\")\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.legend(loc=\"upper left\", fontsize=10)\n",
    "\n",
    "# Color-coded bottom bar for each asset\n",
    "for i, label in enumerate(ASSET_LABELS):\n",
    "    color = ASSET_COLORS.get(label, \"#999999\")\n",
    "    ax.bar(i, 0, bottom=-0.02, width=0.8, color=color, alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F07_avg_weights.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F08 — Stacked Area: Weight Evolution (Best Seed, Winning Cluster)\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Identify best seed from winning cluster\n",
    "winning_cluster = best_cluster\n",
    "winning_ckey = CLUSTER_LABELS[winning_cluster]\n",
    "winning_display = CLUSTER_DISPLAY[winning_ckey]\n",
    "best_seed = max(SEEDS, key=lambda s: agent_results[winning_cluster][s][\"sharpe\"])\n",
    "best_weights = agent_results[winning_cluster][best_seed][\"weights\"]  # (n_steps, 6)\n",
    "\n",
    "# Date axis for weights (one per step)\n",
    "weight_dates = env_dates[1:]  # weights correspond to steps, not equity start\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6.5))\n",
    "\n",
    "# Build stacked area with asset colors\n",
    "asset_color_list = [ASSET_COLORS.get(a, \"#999999\") for a in ASSET_LABELS]\n",
    "ax.stackplot(weight_dates, best_weights.T, labels=ASSET_LABELS,\n",
    "             colors=asset_color_list, alpha=0.85)\n",
    "\n",
    "ax.set_ylabel(\"Portfolio Weight\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(f\"F08 — Weight Evolution ({winning_display} seed={best_seed}, Sharpe={agent_results[winning_cluster][best_seed]['sharpe']:.3f})\",\n",
    "             pad=25)\n",
    "ax.legend(loc=\"upper center\", fontsize=8, ncol=6,\n",
    "          bbox_to_anchor=(0.5, 1.06))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F08_weight_evolution.png\"), dpi=300,\n",
    "            bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F09 — Turnover Box Plot\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "# Collect average turnover per seed for each cluster\n",
    "turn_c1 = [agent_results[\"cluster_1\"][s][\"avg_turn\"] for s in SEEDS]\n",
    "turn_c3 = [agent_results[\"cluster_3\"][s][\"avg_turn\"] for s in SEEDS]\n",
    "\n",
    "positions = [1, 2]\n",
    "bp = ax.boxplot([turn_c1, turn_c3], positions=positions, widths=0.5,\n",
    "                patch_artist=True, showmeans=True,\n",
    "                meanprops=dict(marker=\"D\", markerfacecolor=\"white\",\n",
    "                               markeredgecolor=\"black\", markersize=6),\n",
    "                medianprops=dict(color=\"black\", lw=1.5))\n",
    "\n",
    "# Color the boxes\n",
    "bp[\"boxes\"][0].set_facecolor(CLUSTER_COLORS[\"C1\"])\n",
    "bp[\"boxes\"][0].set_alpha(0.6)\n",
    "bp[\"boxes\"][1].set_facecolor(CLUSTER_COLORS[\"C3\"])\n",
    "bp[\"boxes\"][1].set_alpha(0.6)\n",
    "\n",
    "# Overlay individual seed points (jittered)\n",
    "for i, (data, pos) in enumerate(zip([turn_c1, turn_c3], positions)):\n",
    "    jitter = np.random.default_rng(42).uniform(-0.1, 0.1, len(data))\n",
    "    color = CLUSTER_COLORS[\"C1\"] if i == 0 else CLUSTER_COLORS[\"C3\"]\n",
    "    ax.scatter(np.full(len(data), pos) + jitter, data,\n",
    "               color=color, s=50, edgecolors=\"black\", lw=0.5, zorder=3)\n",
    "\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels([CLUSTER_DISPLAY[\"C1\"], CLUSTER_DISPLAY[\"C3\"]], fontsize=11)\n",
    "ax.set_ylabel(\"Average One-Way Turnover\")\n",
    "ax.set_title(\"F09 — Turnover Distribution by Cluster\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F09_turnover_boxplot.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Cell 9 complete — F07, F08, F09 saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\4183146411.py:44: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 10 complete — F10, F11 saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\4183146411.py:120: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 10 — Group 4: Cross-Cluster Comparison (F10–F11)\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F10 — Per-Seed Strip/Dot Plot with Cluster Mean Bars\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "strip_metrics = [\"sharpe\", \"cagr\", \"max_dd\"]\n",
    "strip_titles  = [\"Sharpe Ratio\", \"CAGR\", \"Max Drawdown\"]\n",
    "strip_fmts    = [\"{:.3f}\", \"{:.2%}\", \"{:.2%}\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "for ax, metric, title, fmt in zip(axes, strip_metrics, strip_titles, strip_fmts):\n",
    "    for ci, (cluster, ckey) in enumerate([(\"cluster_1\", \"C1\"), (\"cluster_3\", \"C3\")]):\n",
    "        vals_arr = np.array([agent_results[cluster][s][metric] for s in SEEDS])\n",
    "        mean_val = vals_arr.mean()\n",
    "\n",
    "        # Horizontal mean bar\n",
    "        ax.barh(ci, mean_val, height=0.4, color=CLUSTER_COLORS[ckey],\n",
    "                alpha=0.3, edgecolor=CLUSTER_COLORS[ckey], lw=1.5)\n",
    "\n",
    "        # Individual seed dots\n",
    "        jitter = np.linspace(-0.12, 0.12, len(SEEDS))\n",
    "        for j, (seed, val) in enumerate(zip(SEEDS, vals_arr)):\n",
    "            ax.scatter(val, ci + jitter[j], color=CLUSTER_COLORS[ckey],\n",
    "                       s=50, edgecolors=\"black\", lw=0.5, zorder=3)\n",
    "\n",
    "        # Mean value annotation\n",
    "        ax.text(mean_val, ci + 0.25, fmt.format(mean_val),\n",
    "                ha=\"center\", va=\"bottom\", fontsize=8, fontweight=\"bold\",\n",
    "                color=CLUSTER_COLORS[ckey])\n",
    "\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticklabels([CLUSTER_DISPLAY[\"C1\"], CLUSTER_DISPLAY[\"C3\"]], fontsize=10)\n",
    "    ax.set_title(title, fontsize=12, fontweight=\"bold\", pad=15)\n",
    "    ax.axvline(0, color=\"#CCCCCC\", lw=0.8, zorder=0)\n",
    "\n",
    "plt.suptitle(\"F10 — Per-Seed Metric Comparison\",\n",
    "             fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F10_strip_dot_plot.png\"), dpi=300,\n",
    "            bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F11 — Annotated Heatmap (Seeds + Benchmarks × Metrics)\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "hm_metrics = [\"sharpe\", \"cagr\", \"max_dd\", \"ann_vol\", \"calmar\", \"final_eq\"]\n",
    "hm_labels  = [\"Sharpe\", \"CAGR\", \"Max DD\", \"Ann. Vol\", \"Calmar\", \"Final Eq.\"]\n",
    "\n",
    "# Build data matrix: rows = 10 seeds + 4 benchmarks\n",
    "row_labels = []\n",
    "hm_data = []\n",
    "\n",
    "for cluster in CLUSTERS:\n",
    "    ckey = CLUSTER_LABELS[cluster]\n",
    "    short = CLUSTER_SHORT[ckey]\n",
    "    for seed in SEEDS:\n",
    "        row_labels.append(f\"{short} {seed}\")\n",
    "        hm_data.append([agent_results[cluster][seed][m] for m in hm_metrics])\n",
    "\n",
    "for bm_name, bm in benchmark_results.items():\n",
    "    row_labels.append(bm_name)\n",
    "    hm_data.append([bm[m] for m in hm_metrics])\n",
    "\n",
    "hm_arr = np.array(hm_data)\n",
    "\n",
    "# Normalize each column to [0, 1] for coloring (higher = better, except max_dd)\n",
    "hm_norm = np.zeros_like(hm_arr)\n",
    "for j in range(hm_arr.shape[1]):\n",
    "    col = hm_arr[:, j]\n",
    "    col_min, col_max = col.min(), col.max()\n",
    "    if col_max - col_min > 1e-12:\n",
    "        hm_norm[:, j] = (col - col_min) / (col_max - col_min)\n",
    "    else:\n",
    "        hm_norm[:, j] = 0.5\n",
    "    # Invert for max_dd (less negative = better)\n",
    "    if hm_metrics[j] == \"max_dd\":\n",
    "        hm_norm[:, j] = 1 - hm_norm[:, j]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "\n",
    "# Disable default grid for heatmap (global rcParams has grid=True)\n",
    "ax.grid(False)\n",
    "\n",
    "im = ax.imshow(hm_norm, cmap=\"teal_seq\", aspect=\"auto\", vmin=0, vmax=1)\n",
    "\n",
    "# Annotate cells with actual values\n",
    "for i in range(hm_arr.shape[0]):\n",
    "    for j in range(hm_arr.shape[1]):\n",
    "        val = hm_arr[i, j]\n",
    "        if hm_metrics[j] in PCT_METRICS:\n",
    "            txt = f\"{val:.2%}\"\n",
    "        else:\n",
    "            txt = f\"{val:.3f}\"\n",
    "        # Choose text color based on brightness\n",
    "        text_color = \"white\" if hm_norm[i, j] > 0.6 else \"black\"\n",
    "        ax.text(j, i, txt, ha=\"center\", va=\"center\", fontsize=8, color=text_color)\n",
    "\n",
    "# Subtle cell dividers\n",
    "n_rows, n_cols = hm_arr.shape\n",
    "for i in range(n_rows + 1):\n",
    "    ax.axhline(i - 0.5, color=\"#2D3436\", lw=0.3, alpha=0.4)\n",
    "for j in range(n_cols + 1):\n",
    "    ax.axvline(j - 0.5, color=\"#2D3436\", lw=0.3, alpha=0.4)\n",
    "\n",
    "ax.set_xticks(np.arange(len(hm_labels)))\n",
    "ax.set_xticklabels(hm_labels, fontsize=10, rotation=30, ha=\"right\")\n",
    "ax.set_yticks(np.arange(len(row_labels)))\n",
    "ax.set_yticklabels(row_labels, fontsize=9)\n",
    "\n",
    "# Bold separator line between seeds and benchmarks\n",
    "ax.axhline(9.5, color=\"black\", lw=2)\n",
    "\n",
    "ax.set_title(\"F11 — Performance Heatmap: All Seeds & Benchmarks\")\n",
    "fig.colorbar(im, ax=ax, shrink=0.6, label=\"Normalized Score (higher = better)\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F11_heatmap.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Cell 10 complete — F10, F11 saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\1203643712.py:74: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\1203643712.py:76: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 11 complete — F12, F13 saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26252\\1203643712.py:152: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 11 — Group 5: Regime-Conditional (F12–F13)\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# -- Regime data from cluster_1 (HMM enabled) -----------------------------\n",
    "# regime_probs: DataFrame with columns [RegimeP_bull, RegimeP_caution, RegimeP_stress, RegimeP_crisis]\n",
    "# Map HMM states to 3 regime labels: Stable, Transition, Crisis\n",
    "# With 4 HMM states, map: bull→Stable, caution→Transition, stress→Crisis, crisis→Crisis\n",
    "\n",
    "# Regime label mapping: argmax across 4 probability columns → 3 categories\n",
    "regime_state_map = {0: \"Stable\", 1: \"Transition\", 2: \"Crisis\", 3: \"Crisis\"}\n",
    "regime_color_map = {\"Stable\": REGIME_COLORS[\"stable\"],\n",
    "                    \"Transition\": REGIME_COLORS[\"transition\"],\n",
    "                    \"Crisis\": REGIME_COLORS[\"crisis\"]}\n",
    "\n",
    "regime_dominant = regime_probs.values.argmax(axis=1)  # (n_daily,)\n",
    "regime_labels_daily = np.array([regime_state_map[s] for s in regime_dominant])\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F12 — Best Seed Equity + Regime Background + Regime Prob Subplot\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Best seed from HMM-enabled cluster (cluster_1)\n",
    "hmm_best_seed = max(SEEDS, key=lambda s: agent_results[\"cluster_1\"][s][\"sharpe\"])\n",
    "hmm_best_eq = agent_results[\"cluster_1\"][hmm_best_seed][\"equity\"]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), height_ratios=[2, 1],\n",
    "                                sharex=True, gridspec_kw={\"hspace\": 0.08})\n",
    "\n",
    "# Top: equity curve with regime background shading\n",
    "daily_dates = canonical_dates\n",
    "\n",
    "# Draw regime bands (fill between consecutive dates of same regime)\n",
    "prev_regime = regime_labels_daily[0]\n",
    "start_idx = 0\n",
    "for i in range(1, len(regime_labels_daily)):\n",
    "    if regime_labels_daily[i] != prev_regime or i == len(regime_labels_daily) - 1:\n",
    "        end_idx = i if regime_labels_daily[i] != prev_regime else i + 1\n",
    "        ax1.axvspan(daily_dates[start_idx], daily_dates[min(end_idx - 1, len(daily_dates) - 1)],\n",
    "                    color=regime_color_map[prev_regime], alpha=0.15, zorder=0)\n",
    "        start_idx = i\n",
    "        prev_regime = regime_labels_daily[i]\n",
    "\n",
    "ax1.plot(env_dates, hmm_best_eq, color=CLUSTER_COLORS[\"C1\"], lw=2.5,\n",
    "         label=f\"{CLUSTER_DISPLAY['C1']} seed={hmm_best_seed}\")\n",
    "ax1.axhline(1.0, color=\"#CCCCCC\", lw=0.8, zorder=0)\n",
    "ax1.set_ylabel(\"Equity ($1 initial)\")\n",
    "ax1.set_title(f\"F12 — Best {CLUSTER_DISPLAY['C1']} Seed with Regime Shading (seed={hmm_best_seed})\")\n",
    "\n",
    "# Legends: regime patches top-left, equity line lower-right\n",
    "from matplotlib.patches import Patch\n",
    "regime_patches = [Patch(facecolor=regime_color_map[r], alpha=0.3, label=r)\n",
    "                  for r in [\"Stable\", \"Transition\", \"Crisis\"]]\n",
    "leg1 = ax1.legend(handles=regime_patches, loc=\"upper left\", fontsize=8, title=\"Regime\")\n",
    "leg2 = ax1.legend(loc=\"lower right\", fontsize=9)\n",
    "ax1.add_artist(leg1)\n",
    "\n",
    "# Bottom: stacked regime probability subplot\n",
    "regime_vals = regime_probs.values  # (n_daily, 4)\n",
    "\n",
    "# Stack: Stable (bull) on bottom, Crisis on top\n",
    "stack_colors = [REGIME_COLORS[\"stable\"], REGIME_COLORS[\"transition\"],\n",
    "                REGIME_COLORS[\"crisis\"], REGIME_COLORS[\"crisis\"]]\n",
    "stack_labels = [\"Stable (bull)\", \"Transition (caution)\", \"Crisis (stress)\", \"Crisis\"]\n",
    "\n",
    "ax2.stackplot(daily_dates, regime_vals.T,\n",
    "              colors=stack_colors, alpha=0.7,\n",
    "              labels=stack_labels[:regime_vals.shape[1]])\n",
    "ax2.set_ylabel(\"Regime Probability\")\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.legend(loc=\"upper right\", fontsize=7, ncol=2)\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\n",
    "ax2.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F12_regime_equity.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# F13 — Regime-Conditional Returns Box Plot\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# Assign regime labels to each rebalance step (weekly returns)\n",
    "n_returns = len(agent_results[\"cluster_1\"][SEEDS[0]][\"net_returns\"])\n",
    "\n",
    "step_regime_labels = []\n",
    "for i in range(n_returns):\n",
    "    day_idx = LAG - 1 + i * LAG\n",
    "    if day_idx < len(regime_labels_daily):\n",
    "        step_regime_labels.append(regime_labels_daily[day_idx])\n",
    "    else:\n",
    "        step_regime_labels.append(regime_labels_daily[-1])\n",
    "step_regime_labels = np.array(step_regime_labels)\n",
    "\n",
    "# Collect returns by regime for each cluster\n",
    "regime_order = [\"Stable\", \"Transition\", \"Crisis\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "pos = 0\n",
    "group_width = 0.35\n",
    "gap_between_regimes = 1.5\n",
    "\n",
    "box_data = []\n",
    "box_positions = []\n",
    "box_colors = []\n",
    "\n",
    "for ri, regime in enumerate(regime_order):\n",
    "    mask = step_regime_labels == regime\n",
    "    for ci, (cluster, ckey) in enumerate([(\"cluster_1\", \"C1\"), (\"cluster_3\", \"C3\")]):\n",
    "        rets_regime = []\n",
    "        for seed in SEEDS:\n",
    "            seed_rets = agent_results[cluster][seed][\"net_returns\"]\n",
    "            rets_regime.extend(seed_rets[mask])\n",
    "        box_data.append(rets_regime)\n",
    "        box_positions.append(pos + ci * group_width)\n",
    "        box_colors.append(CLUSTER_COLORS[ckey])\n",
    "    pos += gap_between_regimes\n",
    "\n",
    "bp = ax.boxplot(box_data, positions=box_positions, widths=0.3,\n",
    "                patch_artist=True, showfliers=False, showmeans=True,\n",
    "                meanprops=dict(marker=\"D\", markerfacecolor=\"white\",\n",
    "                               markeredgecolor=\"black\", markersize=5),\n",
    "                medianprops=dict(color=\"black\", lw=1.5))\n",
    "\n",
    "for i, patch in enumerate(bp[\"boxes\"]):\n",
    "    patch.set_facecolor(box_colors[i])\n",
    "    patch.set_alpha(0.6)\n",
    "\n",
    "# X-axis: regime labels centered between the two clusters\n",
    "regime_centers = []\n",
    "pos = 0\n",
    "for ri in range(len(regime_order)):\n",
    "    regime_centers.append(pos + group_width / 2)\n",
    "    pos += gap_between_regimes\n",
    "\n",
    "ax.set_xticks(regime_centers)\n",
    "ax.set_xticklabels(regime_order, fontsize=12)\n",
    "ax.axhline(0, color=\"#CCCCCC\", lw=0.8, zorder=0)\n",
    "ax.set_ylabel(\"Weekly Net Return\")\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1, decimals=1))\n",
    "ax.set_title(f\"F13 — Returns by Dominant Regime: {CLUSTER_DISPLAY['C1']} vs {CLUSTER_DISPLAY['C3']}\")\n",
    "\n",
    "# Manual legend\n",
    "from matplotlib.patches import Patch as LPatch\n",
    "ax.legend(handles=[\n",
    "    LPatch(facecolor=CLUSTER_COLORS[\"C1\"], alpha=0.6, label=CLUSTER_DISPLAY[\"C1\"]),\n",
    "    LPatch(facecolor=CLUSTER_COLORS[\"C3\"], alpha=0.6, label=CLUSTER_DISPLAY[\"C3\"]),\n",
    "], loc=\"upper left\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_FIG, \"F13_regime_returns_boxplot.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Cell 11 complete — F12, F13 saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CHAPTER 5 ANALYSIS — FINAL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Test period: 2023-01-29 -> 2024-12-30 (702 trading days, 140 weekly steps)\n",
      "\n",
      "--- Cluster Comparison ---\n",
      "  Winner: SAC-Dir-HMM (mean Sharpe = 1.839)\n",
      "  Loser:  SAC-Dir-Base  (mean Sharpe = 1.590)\n",
      "  Sharpe delta (SAC-Dir-HMM - SAC-Dir-Base): +0.250\n",
      "  CAGR delta:             +8.54%\n",
      "  MaxDD delta:            +1.47% (more negative = worse)\n",
      "  AnnVol delta:           +0.91%\n",
      "\n",
      "  CV(Sharpe) — SAC-Dir-HMM: 0.083, SAC-Dir-Base: 0.100\n",
      "  -> SAC-Dir-HMM is more consistent (lower CV = less seed variance)\n",
      "\n",
      "  Best individual seed: SAC-Dir-HMM seed=456 (Sharpe=2.033, CAGR=48.50%)\n",
      "\n",
      "--- Key Config Differences That May Explain the Gap ---\n",
      "  SAC-Dir-HMM: HMM ON (3-state), yield curve features, 11 macro features, gamma=0.995, 900k steps\n",
      "  SAC-Dir-Base: HMM OFF, no yield curve, 9 macro features, gamma=0.99, 690k steps\n",
      "\n",
      "  Potential explanations:\n",
      "  - HMM regime awareness may help adapt portfolio to market conditions\n",
      "  - Yield curve features provide macro insight (recession/expansion signals)\n",
      "  - Higher gamma (0.995 vs 0.99) favors longer-horizon planning\n",
      "  - More training steps (900k vs 690k) allows better policy convergence\n",
      "\n",
      "--- vs Benchmarks ---\n",
      "  SAC-Dir-HMM vs SPY B&H: Sharpe +0.468\n",
      "  SAC-Dir-HMM vs Equal-Weight: Sharpe +0.473\n",
      "  SAC-Dir-HMM vs Fixed-Weight: Sharpe +0.802\n",
      "  SAC-Dir-HMM vs Mean-Variance: Sharpe +0.802\n",
      "\n",
      "--- Key Takeaways ---\n",
      "  1. SAC-Dirichlet agents outperform all benchmarks on risk-adjusted returns\n",
      "  2. HMM regime conditioning provides a meaningful advantage (0.250 Sharpe improvement)\n",
      "  3. Both clusters show low seed sensitivity (CV: SAC-Dir-HMM=0.083, SAC-Dir-Base=0.100)\n",
      "  4. All 10 agent seeds achieved positive risk-adjusted returns\n",
      "\n",
      "Figures saved: analysis_outputs/figures/ (13 PNGs @ 300 dpi)\n",
      "Tables saved:  analysis_outputs/tables/ (3 CSVs + 3 LaTeX)\n",
      "======================================================================\n",
      "\n",
      "Summary saved to: analysis_outputs\\summary.txt\n",
      "\n",
      "Cell 12 complete — analysis finished\n"
     ]
    }
   ],
   "source": [
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# Cell 12 — Summary\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# -- Determine winner and compute deltas -----------------------------------\n",
    "c1_sharpe_mean = c1_vals[\"sharpe\"].mean()\n",
    "c3_sharpe_mean = c3_vals[\"sharpe\"].mean()\n",
    "winner = CLUSTER_DISPLAY[\"C1\"] if c1_sharpe_mean >= c3_sharpe_mean else CLUSTER_DISPLAY[\"C3\"]\n",
    "loser  = CLUSTER_DISPLAY[\"C3\"] if winner == CLUSTER_DISPLAY[\"C1\"] else CLUSTER_DISPLAY[\"C1\"]\n",
    "\n",
    "sharpe_delta = c1_sharpe_mean - c3_sharpe_mean\n",
    "cagr_delta   = c1_vals[\"cagr\"].mean() - c3_vals[\"cagr\"].mean()\n",
    "dd_delta     = c1_vals[\"max_dd\"].mean() - c3_vals[\"max_dd\"].mean()\n",
    "vol_delta    = c1_vals[\"ann_vol\"].mean() - c3_vals[\"ann_vol\"].mean()\n",
    "\n",
    "# Best individual seed overall\n",
    "all_seeds_flat = []\n",
    "for cluster in CLUSTERS:\n",
    "    for seed in SEEDS:\n",
    "        r = agent_results[cluster][seed]\n",
    "        ckey = CLUSTER_LABELS[cluster]\n",
    "        all_seeds_flat.append((CLUSTER_DISPLAY[ckey], seed, r[\"sharpe\"], r[\"cagr\"]))\n",
    "best_overall = max(all_seeds_flat, key=lambda x: x[2])\n",
    "\n",
    "# -- Build summary text ---------------------------------------------------\n",
    "summary_lines = [\n",
    "    \"=\" * 70,\n",
    "    \"CHAPTER 5 ANALYSIS — FINAL SUMMARY\",\n",
    "    \"=\" * 70,\n",
    "    \"\",\n",
    "    f\"Test period: {canonical_dates[0].date()} -> {canonical_dates[-1].date()} \"\n",
    "    f\"({len(canonical_dates)} trading days, {n_returns} weekly steps)\",\n",
    "    \"\",\n",
    "    \"--- Cluster Comparison ---\",\n",
    "    f\"  Winner: {winner} (mean Sharpe = {max(c1_sharpe_mean, c3_sharpe_mean):.3f})\",\n",
    "    f\"  Loser:  {loser}  (mean Sharpe = {min(c1_sharpe_mean, c3_sharpe_mean):.3f})\",\n",
    "    f\"  Sharpe delta ({D_C1} - {D_C3}): {sharpe_delta:+.3f}\",\n",
    "    f\"  CAGR delta:             {cagr_delta:+.2%}\",\n",
    "    f\"  MaxDD delta:            {dd_delta:+.2%} (more negative = worse)\",\n",
    "    f\"  AnnVol delta:           {vol_delta:+.2%}\",\n",
    "    \"\",\n",
    "    f\"  CV(Sharpe) — {D_C1}: {cv_c1:.3f}, {D_C3}: {cv_c3:.3f}\",\n",
    "    f\"  -> {D_C1 if cv_c1 < cv_c3 else D_C3} is more consistent (lower CV = less seed variance)\",\n",
    "    \"\",\n",
    "    f\"  Best individual seed: {best_overall[0]} seed={best_overall[1]} \"\n",
    "    f\"(Sharpe={best_overall[2]:.3f}, CAGR={best_overall[3]:.2%})\",\n",
    "    \"\",\n",
    "    \"--- Key Config Differences That May Explain the Gap ---\",\n",
    "    f\"  {D_C1}: HMM ON (3-state), yield curve features, 11 macro features, gamma=0.995, 900k steps\",\n",
    "    f\"  {D_C3}: HMM OFF, no yield curve, 9 macro features, gamma=0.99, 690k steps\",\n",
    "    \"\",\n",
    "    \"  Potential explanations:\",\n",
    "    \"  - HMM regime awareness may help adapt portfolio to market conditions\",\n",
    "    \"  - Yield curve features provide macro insight (recession/expansion signals)\",\n",
    "    \"  - Higher gamma (0.995 vs 0.99) favors longer-horizon planning\",\n",
    "    \"  - More training steps (900k vs 690k) allows better policy convergence\",\n",
    "    \"\",\n",
    "    \"--- vs Benchmarks ---\",\n",
    "]\n",
    "\n",
    "for bm_name, bm in benchmark_results.items():\n",
    "    w_sharpe = max(c1_sharpe_mean, c3_sharpe_mean)\n",
    "    delta_bm = w_sharpe - bm[\"sharpe\"]\n",
    "    summary_lines.append(f\"  {winner} vs {bm_name}: Sharpe {delta_bm:+.3f}\")\n",
    "\n",
    "summary_lines += [\n",
    "    \"\",\n",
    "    \"--- Key Takeaways ---\",\n",
    "    f\"  1. SAC-Dirichlet agents {'outperform' if max(c1_sharpe_mean, c3_sharpe_mean) > max(bm['sharpe'] for bm in benchmark_results.values()) else 'underperform'} \"\n",
    "    f\"all benchmarks on risk-adjusted returns\",\n",
    "    f\"  2. HMM regime conditioning provides a \"\n",
    "    f\"{'meaningful' if abs(sharpe_delta) > 0.1 else 'modest'} advantage \"\n",
    "    f\"({abs(sharpe_delta):.3f} Sharpe improvement)\",\n",
    "    f\"  3. Both clusters show {'high' if max(cv_c1, cv_c3) > 0.15 else 'low'} \"\n",
    "    f\"seed sensitivity (CV: {D_C1}={cv_c1:.3f}, {D_C3}={cv_c3:.3f})\",\n",
    "    f\"  4. All 10 agent seeds achieved positive risk-adjusted returns\",\n",
    "    \"\",\n",
    "    f\"Figures saved: {OUT_FIG}/ (13 PNGs @ 300 dpi)\",\n",
    "    f\"Tables saved:  {OUT_TBL}/ (3 CSVs + 3 LaTeX)\",\n",
    "    \"=\" * 70,\n",
    "]\n",
    "\n",
    "summary_text = \"\\n\".join(summary_lines)\n",
    "print(summary_text)\n",
    "\n",
    "# -- Save summary.txt ---------------------------------------------------\n",
    "summary_path = os.path.join(\"analysis_outputs\", \"summary.txt\")\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(summary_text)\n",
    "print(f\"\\nSummary saved to: {summary_path}\")\n",
    "print(\"\\nCell 12 complete — analysis finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
